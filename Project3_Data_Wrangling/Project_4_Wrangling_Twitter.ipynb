{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tweet data is stored in JSON format by Twitter. Getting tweet JSON data via tweet ID using Tweepy is described well in this StackOverflow answer. Note that setting the tweet_mode parameter to 'extended' in the get_status call, i.e., api.get_status(tweet_id, tweet_mode='extended'), can be useful.\n",
    "\n",
    "Also, note that the tweets corresponding to a few tweet IDs in the archive may have been deleted. Try-except blocks may come in handy here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction and import of modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project aims to use the tweet archive of twitter user `@dog_rates` also known as `WeRateDogs` . The project focusses on collecting, assessing and cleaning the data collected through the Twitter API using `tweepy`. After Wrangling an analysis is made of the data. The initial estimate of necessary modules is as follows:\n",
    "* pandas\n",
    "* numpy\n",
    "* matplotlib\n",
    "* re\n",
    "* statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import statsmodels.api as sm\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "\n",
    "consumer_key = 'aNTJRrnNf2PI9JXP7AvpkTB4M'\n",
    "consumer_secret = 'bPu9Rcwuyn3ps8JNN6UqzEZYfmWo7RbboC8YcNaCLQ3NicD0Ci'\n",
    "access_token = '92779782-ry7yZqmQq6PvQN9p1dF2pYDo9BBDInMybnwBidmlT'\n",
    "access_secret = 'Rt5d2aEbsq1NXwDwFKnVBogSgmrRnZew4RnQKcFqNfXjm'\n",
    "\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_secret)\n",
    "\n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Description of data sources and import of data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import of data:\n",
    "\n",
    "WeRateDogs Twitter archive is available as a csv file, provided by Udacity. the filename is `twitter_archive_enhanced.csv`\n",
    "\n",
    "The neural network generated file with predictions of dog breeds based on the images in the twitter archive is available from the following website https://d17h27t6h515a5.cloudfront.net/topher/2017/August/599fd2ad_image-predictions/image-predictions.tsv\n",
    "\n",
    "Use the tweet ID's in the archive, to query the twitter API for additional data, write the additional data to `tweet_json.txt`. Gather at minimum\n",
    "* tweet id\n",
    "* Retweet count\n",
    "* favorite count\n",
    "Write each tweets json data to a new line in the `tweet_json.txt` file. use:https://stackabuse.com/reading-and-writing-json-to-a-file-in-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>in_reply_to_status_id</th>\n",
       "      <th>in_reply_to_user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>source</th>\n",
       "      <th>text</th>\n",
       "      <th>retweeted_status_id</th>\n",
       "      <th>retweeted_status_user_id</th>\n",
       "      <th>retweeted_status_timestamp</th>\n",
       "      <th>expanded_urls</th>\n",
       "      <th>rating_numerator</th>\n",
       "      <th>rating_denominator</th>\n",
       "      <th>name</th>\n",
       "      <th>doggo</th>\n",
       "      <th>floofer</th>\n",
       "      <th>pupper</th>\n",
       "      <th>puppo;;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892420643555336193,,,2017-08-01 16:23:56 +0000...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>892177421306343426,,,2017-08-01 00:17:27 +0000...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>891815181378084864,,,2017-07-31 00:18:03 +0000...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>891689557279858688,,,2017-07-30 15:58:51 +0000...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>891327558926688256,,,2017-07-29 16:00:24 +0000...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            tweet_id in_reply_to_status_id  \\\n",
       "0  892420643555336193,,,2017-08-01 16:23:56 +0000...                   NaN   \n",
       "1  892177421306343426,,,2017-08-01 00:17:27 +0000...                   NaN   \n",
       "2  891815181378084864,,,2017-07-31 00:18:03 +0000...                   NaN   \n",
       "3  891689557279858688,,,2017-07-30 15:58:51 +0000...                   NaN   \n",
       "4  891327558926688256,,,2017-07-29 16:00:24 +0000...                   NaN   \n",
       "\n",
       "  in_reply_to_user_id timestamp source text retweeted_status_id  \\\n",
       "0                 NaN       NaN    NaN  NaN                 NaN   \n",
       "1                 NaN       NaN    NaN  NaN                 NaN   \n",
       "2                 NaN       NaN    NaN  NaN                 NaN   \n",
       "3                 NaN       NaN    NaN  NaN                 NaN   \n",
       "4                 NaN       NaN    NaN  NaN                 NaN   \n",
       "\n",
       "  retweeted_status_user_id retweeted_status_timestamp expanded_urls  \\\n",
       "0                      NaN                        NaN           NaN   \n",
       "1                      NaN                        NaN           NaN   \n",
       "2                      NaN                        NaN           NaN   \n",
       "3                      NaN                        NaN           NaN   \n",
       "4                      NaN                        NaN           NaN   \n",
       "\n",
       "  rating_numerator rating_denominator name doggo floofer pupper  puppo;;  \n",
       "0              NaN                NaN  NaN   NaN     NaN    NaN      NaN  \n",
       "1              NaN                NaN  NaN   NaN     NaN    NaN      NaN  \n",
       "2              NaN                NaN  NaN   NaN     NaN    NaN      NaN  \n",
       "3              NaN                NaN  NaN   NaN     NaN    NaN      NaN  \n",
       "4              NaN                NaN  NaN   NaN     NaN    NaN      NaN  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load csv file\n",
    "twitter_archive = pd.read_csv(\"twitter_archive_enhanced.csv\")\n",
    "#check if it worked\n",
    "twitter_archive.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2517 entries, 0 to 2516\n",
      "Data columns (total 17 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   tweet_id                    2517 non-null   object \n",
      " 1   in_reply_to_status_id       8 non-null      object \n",
      " 2   in_reply_to_user_id         3 non-null      object \n",
      " 3   timestamp                   3 non-null      object \n",
      " 4   source                      45 non-null     object \n",
      " 5   text                        52 non-null     object \n",
      " 6   retweeted_status_id         52 non-null     object \n",
      " 7   retweeted_status_user_id    52 non-null     object \n",
      " 8   retweeted_status_timestamp  52 non-null     object \n",
      " 9   expanded_urls               52 non-null     object \n",
      " 10  rating_numerator            52 non-null     object \n",
      " 11  rating_denominator          52 non-null     object \n",
      " 12  name                        9 non-null      object \n",
      " 13  doggo                       7 non-null      object \n",
      " 14  floofer                     4 non-null      object \n",
      " 15  pupper                      2 non-null      object \n",
      " 16  puppo;;                     0 non-null      float64\n",
      "dtypes: float64(1), object(16)\n",
      "memory usage: 334.4+ KB\n"
     ]
    }
   ],
   "source": [
    "twitter_archive.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_archive.at[0, 'timestamp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7461, 35352)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#copied a tweet_id from the csv file for testing purposes with tweepy\n",
    "test_id = '892420643555336193'\n",
    "testtweet = api.get_status(test_id)\n",
    "testtweet.retweet_count, testtweet.favorite_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "        created_at : The time the status was posted.\n",
    "        id : The ID of the status.\n",
    "        id_str : The ID of the status as a string.\n",
    "        text : The text of the status.\n",
    "        entities : The parsed entities of the status such as hashtags, URLs etc.\n",
    "        source : The source of the status.\n",
    "        source_url : The URL of the source of the status.\n",
    "        in_reply_to_status_id : The ID of the status being replied to.\n",
    "        in_reply_to_status_id_str : The ID of the status being replied to in as a string.\n",
    "        in_reply_to_user_id : The ID of the user being replied to.\n",
    "        in_reply_to_user_id_str : The ID of the user being replied to as a string.\n",
    "        in_reply_to_screen_name : The screen name of the user being replied to\n",
    "        user : The User object of the poster of the status.\n",
    "        geo : The geo object of the status.\n",
    "        coordinates : The coordinates of the status.\n",
    "        place : The place of the status.\n",
    "        contributors : The contributors of the status.\n",
    "        is_quote_status : Indicates whether the status is a quoted status or not.\n",
    "        retweet_count : The number of retweets of the status.\n",
    "        favorite_count : The number of likes of the status.\n",
    "        favorited : Indicates whether the status has been favourited by the authenticated user or not.\n",
    "        retweeted : Indicates whether the status has been retweeted by the authenticated user or not.\n",
    "        possibly_sensitive : Indicates whether the status is sensitive or not.\n",
    "        lang : The language of the status.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load additional modules\n",
    "import requests\n",
    "import os\n",
    "# download the image pridections file\n",
    "url = 'https://d17h27t6h515a5.cloudfront.net/topher/2017/August/599fd2ad_image-predictions/image-predictions.tsv'\n",
    "response = requests.get(url)\n",
    "#check if response worked\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#download dog breed predictions file and store in base directory\n",
    "with open('predictions.tsv',mode = 'wb') as file:\n",
    "    file.write(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.ipynb_checkpoints',\n",
       " 'predictions.tsv',\n",
       " 'Project_4_Wrangling_Twitter.ipynb',\n",
       " 'Readme.md',\n",
       " 'twitter_archive_enhanced.csv']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check if file is downloaded\n",
    "os.listdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# Data Wrangling\n",
    "\n",
    "Key points for data wrangling in the assignment\n",
    "Key Points\n",
    "\n",
    "Key points to keep in mind when data wrangling for this project:\n",
    "\n",
    " * You only want original ratings (no retweets) that have images. Though there are 5000+ tweets in the dataset, not all are dog ratings and some are retweets.\n",
    " * Assessing and cleaning the entire dataset completely would require a lot of time, and is not necessary to practice and demonstrate your skills in data wrangling. Therefore, the requirements of this project are only to assess and clean at least 8 quality issues and at least 2 tidiness issues in this dataset.\n",
    " * Cleaning includes merging individual pieces of data according to the rules of tidy data. The fact that the rating numerators are greater than the denominators does not need to be cleaned. This unique rating system is a big part of the popularity of WeRateDogs.\n",
    " * You do not need to gather the tweets beyond August 1st, 2017. You can, but note that you won't be able to gather the image predictions for these tweets since you don't have access to the algorithm used.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Assesment\n",
    "\n",
    "After gathering each of the above pieces of data, assess them visually and programmatically for quality and tidiness issues. Detect and document at least eight (8) quality issues and two (2) tidiness issues "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2517 entries, 0 to 2516\n",
      "Data columns (total 17 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   tweet_id                    2517 non-null   object \n",
      " 1   in_reply_to_status_id       8 non-null      object \n",
      " 2   in_reply_to_user_id         3 non-null      object \n",
      " 3   timestamp                   3 non-null      object \n",
      " 4   source                      45 non-null     object \n",
      " 5   text                        52 non-null     object \n",
      " 6   retweeted_status_id         52 non-null     object \n",
      " 7   retweeted_status_user_id    52 non-null     object \n",
      " 8   retweeted_status_timestamp  52 non-null     object \n",
      " 9   expanded_urls               52 non-null     object \n",
      " 10  rating_numerator            52 non-null     object \n",
      " 11  rating_denominator          52 non-null     object \n",
      " 12  name                        9 non-null      object \n",
      " 13  doggo                       7 non-null      object \n",
      " 14  floofer                     4 non-null      object \n",
      " 15  pupper                      2 non-null      object \n",
      " 16  puppo;;                     0 non-null      float64\n",
      "dtypes: float64(1), object(16)\n",
      "memory usage: 334.4+ KB\n"
     ]
    }
   ],
   "source": [
    "twitter_archive.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'892420643555336193,,,2017-08-01 16:23:56 +0000,\"<a href=\"\"http://twitter.com/download/iphone\"\" rel=\"\"nofollow\"\">Twitter for iPhone</a>\",This is Phineas. He\\'s a mystical boy. Only ever appears in the hole of a donut. 13/10 https://t.co/MgUWQ76dJU,,,,https://twitter.com/dog_rates/status/892420643555336193/photo/1,13,10,Phineas,None,None,None,None;;'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_archive.at[0,'tweet_id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data tidyness\n",
    "\n",
    "* .csv file, all data in one column, no consistent deliminator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data quality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Issues and solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### storing the data\n",
    "Store the clean DataFrame(s) in a CSV file with the main one named `twitter_archive_master.csv`. If additional files exist because multiple tables are required for tidiness, name these files appropriately. Additionally, you may store the cleaned data in a SQLite database (which is to be submitted as well if you do)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis\n",
    "\n",
    ". At least three (3) insights and one (1) visualization must be produced."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data transformation and augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prelimenary analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions\n",
    "\n",
    "Create a 300-600 word written report called `wrangle_report.pdf` or `wrangle_report.html` that briefly describes your wrangling efforts. This is to be framed as an internal document.\n",
    "\n",
    "Create a 250-word-minimum written report called `act_report.pdf` or `act_report.html` that communicates the insights and displays the visualization(s) produced from your wrangled data. This is to be framed as an external document, like a blog post or magazine article, for example.\n",
    "\n",
    "Both of these documents can be created in separate Jupyter Notebooks using the Markdown functionality of Jupyter Notebooks, then downloading those notebooks as PDF files or HTML files (see image below). You might prefer to use a word processor like Google Docs or Microsoft Word, however."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
